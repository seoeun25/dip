dip.jdbc.driver=com.mysql.jdbc.Driver
dip.jdbc.url=jdbc:mysql://localhost/dip?useUnicode=true&characterEncoding=UTF-8
dip.jdbc.username=sa
dip.jdbc.password=sa
dip.create.db.schema=true
dip.pool.max.active.conn=10
dip.validate.db.connection=true
dip.validate.db.connection.eviction.interval=300000
dip.validate.db.connection.eviction.num=10
dip.validate.db.connection.query=select 1
dip.connection.data.source=org.apache.commons.dbcp.BasicDataSource

## dip echo system info
dip.user.name=ndap
dip.schemaregistry.url=http://aih013.nexr.com:18181/repo
dip.load.task.count=10
dip.load.logdir=/home/ndap/dip/logs
dip.load.execution.timezone=Asia/Seoul
dip.kafka.max.pull.size=20900400
dip.kafka.broker=aih013.nexr.com:9092,aih014.nexr.com:9092,aih015.nexr.com:9092
dip.etl.count.dir=/user/seoeun/dip/result
dip.hadoop.conf.dir=/etc/hadoop/conf
dip.namenode=hdfs://ndap
dip.jobtracker=ndap
dip.hiveserver=aih018.nexr.com:10000
dip.hiveserver.user=ndap
dip.hiveserver.passwd=ndap
dip.oozie=http://aih018.nexr.com:11000/oozie

# polling interval of wf wfStatus. ms.
dip.wf.monitor.interval=10000
dip.execution.topic.interval=120000
dip.hive.partition.createddl=ALTER TABLE ${table_name} ADD IF NOT EXISTS PARTITION (ins_date= '${partition}') location '${location}'
dip.schedule.retry.max=3
dip.etl.destination.path=/user/ndap/dip/srcinfos
dip.etl.execution.base.path=/user/ndap/camus/${topic}/exec
dip.etl.execution.history.path=/user/ndap/camus/${topic}/exec/history

## dip srcinfos
dip.avro.topics=
dip.text.topics=

# dip load interval in milliseconds
# 1 hour
dip.load.schedule.interval=3600000
dip.load.schedule.employee.interval=600000
dip.load.schedule.hello.interval=600000






